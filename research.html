<!DOCTYPE HTML>
<html>

<head>
  <title>Research</title>
  <meta name="description" content="website description" />
  <meta name="keywords" content="website keywords, website keywords" />
  <meta http-equiv="content-type" content="text/html; charset=windows-1252" />
  <link rel="stylesheet" type="text/css" href="style/style.css" />

  <link rel="stylesheet" type="text/css" href="style/style.css" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">





<!--
      BODY OF RESEARCH
 -->
<body>
  <div id="main">
    <div id="header">
      <div id="logo">
        <div id="logo_text">
          <h1>Parshan Pakiman</h1>
        </div>
      </div>
      <div id="menubar">
        <ul id="menu">
          <li>                  <a href="vita.html">      Vita       </a></li>
          <!-- <li>                  <a href="email.html">     Email      </a></li> -->
          <li>                  <a href="talks.html">  Talks     </a></li>
          <li class="selected"> <a href="research.html">  Research   </a></li>
          <li>                  <a href="index.html">     Home       </a></li>
        </ul>
      </div>
    </div>
    <div id="site_content_wide">

    <h3 style="padding:0;margin: 0;font-weight: bold;">Published or Submitted Papers </h2>


    <!--
            Item
    -->
    <div class="container">
          <div id="year">
            <div id="yearItem"> January 2020 </div>
          </div>
          <div id="publisher">
            <div id="publisherItem">   </div>
          </div>
          <div id="paperTitle">
            <div id="paperTitleItem">
              Self-guided Approximate Linear Programs, with
                <i>
                  Selvaprabu Nadarajah, Negar Soheili, and Qihang Lin.
                </i>
                <b>
                    (Major Revision at Management Science).
                </b>
            </div>
          </div>

          <div id="relatedLinks">
                  <!--link-->
                  <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3512665" target="_blank">
                    <i id=activeLink  class="fa">&#xf0c1;</i>
                  </a>
                  <!--U TUBE-->
                    <i id='inactiveLink' class="fa">&#xf167;</i>
                  <span style="display:inline-block; width: 2px;"></span>
                  <!--CODE-->
                  <a href="https://github.com/Self-guided-Approximate-Linear-Programs" target="_blank">
                    <i id=activeLink class="fa">&#xf1c9;</i>
                  </a>

          </div>

          <div id="abstract">
              <div class="content">
                <p class="js-excerpt excerpt-hidden" style="line-height: 1.2em;text-indent: 0px;">
                <b> Abstract: </b>
                	Approximate linear programs (ALPs) are well-known models based
                  on value function approximations (VFAs) to obtain heuristic policies
                  and lower bounds on the optimal policy cost of Markov decision processes
                  (MDPs). The ALP VFA is a linear combination of predefined basis
                  functions that are chosen using domain knowledge and updated heuristically
                  if the ALP optimality gap is large. We side-step the need for such basis
                  function engineering in ALP - an implementation bottleneck - by proposing
                  a sequence of ALPs that embed increasing numbers of random basis functions
                  obtained via inexpensive sampling. We provide a sampling guarantee and
                  show that the VFAs from this sequence of models converge to the exact
                  value function. Nevertheless, the performance of the ALP policy can
                  fluctuate significantly as more basis functions are sampled.
                  To mitigate these fluctuations, we "self-guide" our convergent
                  sequence of ALPs using past VFA information such that a worst-case
                  measure of policy performance is improved. We perform numerical
                  experiments on perishable inventory control and generalized joint
                  replenishment applications, which, respectively, give rise to
                  challenging discounted-cost MDPs and average-cost semi-MDPs. We find that self-guided ALPs (i) significantly reduce policy cost fluctuations and improve the optimality gaps from an ALP approach that employs basis functions tailored to the former application, and (ii) deliver optimality gaps that are comparable to a known adaptive basis function generation approach targeting the latter application. More broadly, our methodology provides application-agnostic policies and lower bounds to benchmark approaches that exploit application structure.
              </p>
            </div>
            <a role="button" href="#" class="js-show-more">Show more</a>
            </div>


        </div>



      <!--
              Item
      -->
      <div class="container">
            <div id="year">
              <div id="yearItem"> August 2019 </div>
            </div>
            <div id="publisher">
              <div id="publisherItem">  </div>
            </div>
            <div id="paperTitle">
              <div id="paperTitleItem">
                  SMOILE: A Shopper Marketing Optimization and Inverse Learning Engine,
                  with
                  <i>
                      Abhilash Reddy Chenreddy, Selvaprabu Nadarajah,
                      Ranganathan Chandrasekaran, and Rick Abens.
                  </i>
                  <b>
                      In The 25th ACM SIGKDD Conference on Knowledge Discovery and Data Mining
                  </b>
                  (Acceptance rate for oral presentation 6.4%).


              </div>
            </div>

            <div id="relatedLinks">

                    <!--link-->
                    <a href="https://doi.org/10.1145/3292500.3330788" target="_blank">
                      <i id=activeLink  class="fa">&#xf0c1;</i>
                    </a>
                    <span style="display:inline-block; width: 2px;"></span>
                    <!--U TUBE-->
                      <a href="https://www.youtube.com/playlist?list=PL0RicIgDjGEyYSJfxuPNXoWxzDU0PlPzr" target="_blank">
                        <i id='activeLink' class="fa">&#xf167;</i>
                      </a>
                    <span style="display:inline-block; width: 2px;"></span>
                    <!--CODE-->
                      <i id=inactiveLink class="fa">&#xf1c9;</i>

            </div>

            <div id="abstract">
                <div class="content">
                    <p class="js-excerpt excerpt-hidden" style="line-height: 1.2em;text-indent: 0px;">
                    <b> Abstract: </b>
                    Product brands employ shopper marketing (SM) strategies to convert
                    shoppers along the path to purchase. Traditional marketing mix models (MMMs),
                    which leverage regression techniques and historical data,
                    can be used to predict the component of sales lift due to SM tactics.
                    The resulting predictive model is a critical input to plan future SM strategies.
                    The implementation of traditional MMMs, however, requires significant
                    ad-hoc manual intervention due to their limited flexibility in (i)
                    explicitly capturing the temporal link between decisions; (ii) accounting for
                    the interaction between business rules and past (sales and decision)
                    data during the attribution of lift to SM; and (iii) ensuring that
                    future decisions adhere to business rules. These issues necessitate
                    MMMs with tailored structures for specific products and retailers,
                    each requiring significant hand-engineering to achieve satisfactory
                    performance - a major implementation challenge.
                    <br><br>
                    We propose an SM Optimization and Inverse Learning Engine (SMOILE)
                    that combines optimization and inverse reinforcement learning to
                    streamline implementation. SMOILE learns a model of lift by viewing SM
                    tactic choice as a sequential process, leverages inverse reinforcement learning
                    to explicitly couple sales and decision data, and employs an optimization
                    approach to handle a wide-array of business rules. Using a unique dataset
                    containing sales and SM spend information across retailers and products,
                    we illustrate how SMOILE standardizes the use of data to prescribe
                    future SM decisions. We also track an industry benchmark to showcase the
                    importance of encoding SM lift and decision structures to mitigate spurious
                    results when uncovering the impact of SM decisions.
                  </p>
                </div>
                <a role="button" href="#" class="js-show-more">Show more</a>
              </div>


          </div>
            <h3 style="padding:0;margin: 0; font-weight: bold;"> Working Papers </h2>



          <!--
                      Item
          -->
          <div class="container">
                <div id="year">
                  <div id="yearItem"> Present </div>
                </div>
                <div id="publisher">
                  <div id="publisherItem">   </div>
                </div>
                <div id="paperTitle">
                  <div id="paperTitleItem">
                      Self-adapting Robustness in Demand Learning, with
                      <i>
                        Boxiao (Beryl) Chen, Selvaprabu Nadarajah and Stefanus Jasin.
                      </i>
                      <b>
                          (Draft is available upon request).
                      </b>
                  </div>
                </div>

                <div id="relatedLinks">
                        <!--link-->
                          <i id=inactiveLink  class="fa">&#xf0c1;</i>
                          <span style="display:inline-block; width: 2px;"></span>
                        <!--U TUBE-->
                        <a href="https://youtu.be/DrioI3lLiUc" target="_blank">
                          <i id='activeLink' class="fa">&#xf167;</i>
                        </a>
                        <span style="display:inline-block; width: 2px;"></span>
                        <!--CODE-->
                          <i id=inactiveLink class="fa">&#xf1c9;</i>

                </div>

                  <div id="abstract">
                      <div class="content">
                          <p class="js-excerpt excerpt-hidden" style="line-height: 1.2em;text-indent: 0px;">
                          <b> Abstract: </b>
                          We study dynamic pricing over a finite number of periods
                          in the presence of demand-model ambiguity. Departing from the
                          typical no-regret learning environment, where price changes are
                          intervals and each price can apply to a large number of arrivals.
                          In this environment, which arises in retailing, a pricing decision
                          based on an incorrect demand-model can significantly impact
                          cumulative revenue. We develop an adaptively-robust-learning (ARL)
                          pricing policy that learns the true model parameters from data while
                          actively managing demand-model ambiguity. It optimizes an objective
                          that is robust with respect to a self-adapting set of demand models,
                          where a given model is included in this set if the sales data revealed
                          from prior pricing decisions makes it "plausible". As a result, it
                          gracefully transitions from being robust when demand-model ambiguity is
                          high to minimizing regret when this ambiguity diminishes upon receiving
                          more data. We characterize the stochastic behavior of ARL's self-adapting
                          ambiguity sets and derive a regret bound that highlights the link between
                          the scale of revenue loss and the customer arrival pattern. We also show that ARL,
                          by being conscious of both model risk and revenue,
                          bridges the gap between a distributionally robust policy and a follow-the-leader
                          policy, which focus on model risk and revenue, respectively. We numerically find
                          that the ARL policy exhibits superior performance compared to distributionally
                          robust, follow-the-leader, and upper-confidence-bound policies,
                          as well as an extension, in terms of expected profit and/or value at risk.
                        </p>
                      </div>
                      <a role="button" href="#" class="js-show-more">Show more</a>
                    </div>


                </div>


            <!--
                        Item
            -->
            <div class="container">
                  <div id="year">
                    <div id="yearItem"> Present </div>
                  </div>
                  <div id="publisher">
                    <div id="publisherItem">   </div>
                  </div>
                  <div id="paperTitle">
                    <div id="paperTitleItem">
                        Managing packing efficiency and sustainability in e-commerce: A semi-supervised learning approach, with
                        <i>
                          Selvaprabu Nadarajah and Yun Fong Lim.
                        </i>
                        <b>
                            (Work in progress).
                        </b>
                    </div>
                  </div>

                  <div id="relatedLinks">
                          <!--link-->
                            <i id=inactiveLink  class="fa">&#xf0c1;</i>
                            <span style="display:inline-block; width: 2px;"></span>
                          <!--U TUBE-->
                            <a href="https://us-lti.bbcollab.com/collab/ui/session/playback" target="_blank">
                                <i id='activeLink' class="fa">&#xf167;</i>
                            </a>
                          <span style="display:inline-block; width: 2px;"></span>
                          <!--CODE-->
                            <i id=inactiveLink class="fa">&#xf1c9;</i>

                  </div>

                    <div id="abstract">
                        <div class="content">
                            <p class="js-excerpt excerpt-hidden" style="line-height: 1.2em;text-indent: 0px;">
                            <b> Abstract: </b>
                            On average, 165 billion packages are shipped annually in the United States, which requires unprecedented amounts of packaging material including cardboard boxes and void-fill material. We leverage the box suite, that is the collection of box types available to workers for packing items, as a lever for better aligning two seemingly competing objectives. These are (i) reducing packaging material used by e-commerce, that is, being cost-effective and environmentally responsible; and (ii) sustaining the efficiency of workers during high demand. We develop a semi-supervised learning framework that jointly models worker efficiency and the optimization of the box suite. We evaluate the performance of our framework using a unique dataset provided by a major e-commerce company.
                          </p>
                        </div>
                        <a role="button" href="#" class="js-show-more">Show more</a>
                      </div>


                  </div>





              <!--
                      Item
              -->
              <div class="container">
                    <div id="year">
                      <div id="yearItem"> Present </div>
                    </div>
                    <div id="publisher">
                      <div id="publisherItem">   </div>
                    </div>
                    <div id="paperTitle">
                      <div id="paperTitleItem">
                          Convex Optimization using Random Features, with
                          <i>
                            Negar Soheili and Selvaprabu Nadarajah.
                          </i>
                          <b>
                              (Work in progress).
                          </b>
                      </div>
                    </div>

                    <div id="relatedLinks">
                            <!--link-->
                              <i id=inactiveLink  class="fa">&#xf0c1;</i>
                              <span style="display:inline-block; width: 2px;"></span>
                            <!--U TUBE-->
                              <i id='inactiveLink' class="fa">&#xf167;</i>
                              </a>
                            <span style="display:inline-block; width: 2px;"></span>
                            <!--CODE-->
                              <i id=inactiveLink class="fa">&#xf1c9;</i>

                    </div>

                    <div id="abstract">
                        <div class="content">
                            <p class="js-excerpt excerpt-hidden">

                          </p>
                        </div>
                        <!-- <a role="button" href="#" class="js-show-more">Show more</a> -->
                    </div>


                </div>









    </div>


<script src="style/scripts.js"></script>
</body>
</html>
